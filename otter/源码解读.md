http://eyuxu.iteye.com/blog/1942518

工程结构：
    manager：管理节点，逻辑上只有一个，一个manager管理多个node节点，如果不考虑HA，负责管理同步的数据定义，包括数据源
    channel、pipeline、数据映射等 。node节点从manager处获取并执行这些信息，另外还有监控等信息。
        biz
        deployer
        web
    node：一个独痒痒部署的节点，比如两个机户需要做通讯，则每个机房至少要部署一个node节点，数据同步的过程实际上都发生在node之间。
        canal：canal的封装，otter采用的是Embed的方式引入canal。canal有embed和独立运行的两种模式。
        common：公共内容定义
        deployer：内置jetty的启动
        etl：SETL调度，处理的实现，是Otter最复杂，最核心的部份。
        extend
    shared：是node和manager共享的子系统
        arbitrate：
        common：公共内容定义
        communication：数据传输的底层，上层的pipe、一些调度等都是依赖于communication的，简单点说它负责点对点的event发送和接收。
        etl：实际上并不负责etl的具体实现，只是一些接口&数据结构的定义而已，具体实现在node里面。
        push
    
### 数据库反查
正常同步的内容是基于binlog的。即binlog有什么数据就同步什么数据，但是如果同步的数据延迟时间比较长的话，可能在同步的数据已经发生变化，即binlog里面的数据已经是旧数据了，为了避免这个问题，在extract阶段根据条件进行查询数据。com.alibaba.otter.node.etl.extract.extractor.DatabaseExtractor

### canal
canal基础的框架包括以下几个部份，MetaManager、EventParser、EventSink、EventStore，其中EventParser的作用是发送dump命令，从mysql数据库获取binlog文件。发送dump命令，可以指定时间戳或者position，从指定的时间或者们置开始dump。

#### EventStore
* 维护一个类似于Disruptor的RingBuffer，同时维护三个序列，put/get/ack。
* EventSink之后的数据，调用put接口，将数据放入环形队列中。
* Canal client获取数据，调用get方法。
* 异步调用ack方法，清除ack之前的数据。
* get和ack采用了流式API模式，get和ack异步进行，可以先get，然后异步调用ack。ack是有序的，不允许跳跃式的提交。
